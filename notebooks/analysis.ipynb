{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Data-Engineering\\fetch-homework-assignment\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the file as NDJSON...\n",
      "File successfully loaded as NDJSON.\n",
      "DataFrame loaded successfully!\n",
      "                                    _id  bonusPointsEarned  \\\n",
      "0  {'$oid': '5ff1e1eb0a720f0523000575'}              500.0   \n",
      "1  {'$oid': '5ff1e1bb0a720f052300056b'}              150.0   \n",
      "2  {'$oid': '5ff1e1f10a720f052300057a'}                5.0   \n",
      "3  {'$oid': '5ff1e1ee0a7214ada100056f'}                5.0   \n",
      "4  {'$oid': '5ff1e1d20a7214ada1000561'}                5.0   \n",
      "\n",
      "                             bonusPointsEarnedReason  \\\n",
      "0  Receipt number 2 completed, bonus point schedu...   \n",
      "1  Receipt number 5 completed, bonus point schedu...   \n",
      "2                         All-receipts receipt bonus   \n",
      "3                         All-receipts receipt bonus   \n",
      "4                         All-receipts receipt bonus   \n",
      "\n",
      "                 createDate               dateScanned  \\\n",
      "0  {'$date': 1609687531000}  {'$date': 1609687531000}   \n",
      "1  {'$date': 1609687483000}  {'$date': 1609687483000}   \n",
      "2  {'$date': 1609687537000}  {'$date': 1609687537000}   \n",
      "3  {'$date': 1609687534000}  {'$date': 1609687534000}   \n",
      "4  {'$date': 1609687506000}  {'$date': 1609687506000}   \n",
      "\n",
      "               finishedDate                modifyDate  \\\n",
      "0  {'$date': 1609687531000}  {'$date': 1609687536000}   \n",
      "1  {'$date': 1609687483000}  {'$date': 1609687488000}   \n",
      "2                       NaN  {'$date': 1609687542000}   \n",
      "3  {'$date': 1609687534000}  {'$date': 1609687539000}   \n",
      "4  {'$date': 1609687511000}  {'$date': 1609687511000}   \n",
      "\n",
      "          pointsAwardedDate  pointsEarned              purchaseDate  \\\n",
      "0  {'$date': 1609687531000}         500.0  {'$date': 1609632000000}   \n",
      "1  {'$date': 1609687483000}         150.0  {'$date': 1609601083000}   \n",
      "2                       NaN           5.0  {'$date': 1609632000000}   \n",
      "3  {'$date': 1609687534000}           5.0  {'$date': 1609632000000}   \n",
      "4  {'$date': 1609687506000}           5.0  {'$date': 1609601106000}   \n",
      "\n",
      "   purchasedItemCount                             rewardsReceiptItemList  \\\n",
      "0                 5.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "1                 2.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "2                 1.0  [{'needsFetchReview': False, 'partnerItemId': ...   \n",
      "3                 4.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "4                 2.0  [{'barcode': '4011', 'description': 'ITEM NOT ...   \n",
      "\n",
      "  rewardsReceiptStatus  totalSpent                    userId  \n",
      "0             FINISHED        26.0  5ff1e1eacfcf6c399c274ae6  \n",
      "1             FINISHED        11.0  5ff1e194b6a9d73a3a9f1052  \n",
      "2             REJECTED        10.0  5ff1e1f1cfcf6c399c274b0b  \n",
      "3             FINISHED        28.0  5ff1e1eacfcf6c399c274ae6  \n",
      "4             FINISHED         1.0  5ff1e194b6a9d73a3a9f1052  \n",
      "Data successfully saved to: ../data/receipts_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# File path to the JSON file\n",
    "file_path = \"../data/receipts.json\"\n",
    "output_path = \"../data/receipts_fixed.json\"\n",
    "\n",
    "\n",
    "def preprocess_json(file_path, output_path):\n",
    "    \"\"\"\n",
    "    Preprocesses a malformed JSON file to wrap all objects into a valid JSON array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()  # Read the file line by line\n",
    "\n",
    "        # Convert each line into a JSON object\n",
    "        json_objects = [json.loads(line) for line in lines]\n",
    "\n",
    "        # Write the objects into a proper JSON array\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(json_objects, f, indent=4)\n",
    "\n",
    "        print(f\"File successfully converted to valid JSON: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads JSON or NDJSON data into a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to load as NDJSON\n",
    "        print(\"Attempting to load the file as NDJSON...\")\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        print(\"File successfully loaded as NDJSON.\")\n",
    "        return df\n",
    "    except ValueError:\n",
    "        print(\"File is not NDJSON. Attempting to preprocess...\")\n",
    "\n",
    "        # Preprocess the file to fix formatting issues\n",
    "        fixed_path = preprocess_json(file_path, output_path)\n",
    "        if not fixed_path:\n",
    "            raise Exception(\"Preprocessing failed. Could not fix the file.\")\n",
    "\n",
    "        # Load the fixed JSON file\n",
    "        print(\"Loading the fixed JSON file...\")\n",
    "        df = pd.read_json(fixed_path)\n",
    "        print(\"File successfully loaded after preprocessing.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    else:\n",
    "        # Load the data into a DataFrame\n",
    "        df = load_data(file_path)\n",
    "\n",
    "        if df is not None:\n",
    "            # Display the first few rows of the DataFrame\n",
    "            print(\"DataFrame loaded successfully!\")\n",
    "            print(df.head())\n",
    "\n",
    "            # Optionally save the DataFrame to a CSV file\n",
    "            csv_output_path = \"../data/receipts_cleaned.csv\"\n",
    "            df.to_csv(csv_output_path, index=False)\n",
    "            print(f\"Data successfully saved to: {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the top 5 brands by receipts scanned for most recent month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
